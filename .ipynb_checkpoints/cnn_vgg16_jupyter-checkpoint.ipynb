{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rutas de directorios de datos\n",
    "train_dir = './DATA/TRAIN'\n",
    "val_dir = './DATA/VAL'\n",
    "test_dir = './DATA/TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de las imágenes\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el preprocesamiento de imágenes y generadores de datos\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelo VGG16 pre-entrenado sin la capa densa superior\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar capas densas superiores personalizadas\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir el modelo base y las capas densas personalizadas\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar los pesos del modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# Mostrar arquitectura del modelo en imagen\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "img = plt.imread('model.png')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Crear el grafo de networkx a partir del modelo\n",
    "graph = nx.DiGraph()\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'output'):\n",
    "        for output_node in layer.output:\n",
    "            graph.add_edge(layer.name, output_node.name)\n",
    "\n",
    "# Crear el grafo de matplotlib a partir del grafo de networkx\n",
    "pos = nx.nx_agraph.graphviz_layout(graph, prog='dot')\n",
    "nx.draw_networkx_nodes(graph, pos, node_size=500)\n",
    "nx.draw_networkx_edges(graph, pos, arrows=True)\n",
    "nx.draw_networkx_labels(graph, pos, font_size=10, font_family='sans-serif')\n",
    "\n",
    "# Mostrar el grafo\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir callbacks\n",
    "early_stop = EarlyStopping(patience=5)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "        callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la curva de pérdida\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.title('Curva de pérdida')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.show()\n",
    "\n",
    "# Graficar la curva de precisión\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.title('Curva de precisión')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar resultados de entrenamiento y evaluación\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo con conjunto de prueba\n",
    "model.load_weights('best_model.h5')\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from metrics import confusion_matrix\n",
    "\n",
    "# Obtener las etiquetas predichas para los datos de prueba\n",
    "y_pred = modelo.predict(test_generator)\n",
    "\n",
    "# Convertir las etiquetas predichas en clases (0 o 1) mediante umbral de 0.5\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Obtener las verdaderas clases para los datos de prueba\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Obtener la lista de etiquetas (nombres de las clases) a partir del generador\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "print('Matriz de confusión:')\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import classification_report\n",
    "\n",
    "# Cargar los pesos del modelo\n",
    "model.load_weights('best_model.h5')\n",
    "\n",
    "# Obtener las predicciones del modelo en el conjunto de prueba\n",
    "predictions = model.predict_generator(test_generator)\n",
    "\n",
    "# Obtener las etiquetas verdaderas del conjunto de prueba\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Obtener el reporte de clasificación para cada clase\n",
    "report = classification_report(true_labels, np.argmax(predictions, axis=1), target_names=test_generator.class_indices.keys(), output_dict=True)\n",
    "\n",
    "# Crear una figura de barras para la precisión, recuperación y puntuación F1\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ind = np.arange(len(report.keys())-3)\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(['precision', 'recall', 'f1-score']):\n",
    "    scores = [report[label][metric] for label in test_generator.class_indices.keys()]\n",
    "    ax.bar(ind+i*width, scores, width, label=metric)\n",
    "\n",
    "ax.set_xticks(ind + width)\n",
    "ax.set_xticklabels(test_generator.class_indices.keys())\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.set_xlabel('Clases')\n",
    "ax.set_ylabel('Valor')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir una imagen\n",
    "def classify_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_width, img_height))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x / 255.0\n",
    "\n",
    "    prediction = model.predict(x)[0]\n",
    "\n",
    "    classes = ['Normal', 'Neumonia_Bacteria', 'Neumonia_Virus']\n",
    "    for i in range(len(classes)):\n",
    "        print(f'{classes[i]}: {prediction[i] * 100:.2f}%')\n",
    "\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    return classes[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_width, img_height))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x / 255.0\n",
    "\n",
    "    prediction = model.predict(x)[0]\n",
    "\n",
    "    classes = ['Normal', 'Neumonia_Bacteria', 'Neumonia_Virus']\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    # Crear dos subplots: uno para la imagen y otro para las probabilidades\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    \n",
    "    # Mostrar la imagen en el primer subplot\n",
    "    ax1.imshow(img)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('Imagen')\n",
    "\n",
    "    # Crear una lista de colores para las barras de las probabilidades\n",
    "    colors = ['g' if i == predicted_class else 'r' for i in range(len(classes))]\n",
    "\n",
    "    # Mostrar las probabilidades en un gráfico de barras horizontal en el segundo subplot\n",
    "    ax2.barh(classes, prediction * 100, color=colors)\n",
    "    ax2.set_xlim([0, 100])\n",
    "    ax2.set_title('Probabilidades')\n",
    "    ax2.set_xlabel('%')\n",
    "\n",
    "    # Ajustar los subplots y mostrar la figura\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return classes[predicted_class]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
